{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eye Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZJLnEBkUEDX",
        "outputId": "618d8c25-5a75-49e7-b6c9-e27d188bdcd7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 16 17:22:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K23A4arwR93q"
      },
      "source": [
        "# !pip install torch\n",
        "# !python -m pip install git+https://github.com/nicolas-chaulet/torch-points3d.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YKEFgp4SGEm"
      },
      "source": [
        "# !mkdir -p torch_points3d/datasets/segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F28HPCBmFOW",
        "outputId": "ddb95a0a-0fff-4cfd-af8c-d88fe404190a"
      },
      "source": [
        "# !pip3 install torch torchvision torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu102)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57OPjlCynJKU",
        "outputId": "358b8c47-f44a-4e79-b557-4be52b00b163"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L_EDDmDrr7P",
        "outputId": "01b24fdc-e0b0-434b-f69b-3a5d38df4a77"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzuCizoTUnFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10877f8-56e0-499c-9621-cfe687697231"
      },
      "source": [
        "!wget --no-check-certificate https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-16 17:19:59--  https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 706988960 (674M) [application/zip]\n",
            "Saving to: ‘shapenetcore_partanno_segmentation_benchmark_v0_normal.zip’\n",
            "\n",
            "shapenetcore_partan 100%[===================>] 674.24M  16.5MB/s    in 68s     \n",
            "\n",
            "2021-06-16 17:21:07 (9.92 MB/s) - ‘shapenetcore_partanno_segmentation_benchmark_v0_normal.zip’ saved [706988960/706988960]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xknxjNMFjtXV",
        "outputId": "f7bbbea0-02ee-40eb-bfc4-a09418ecdec5"
      },
      "source": [
        "!git clone https://github.com/qq456cvb/Point-Transformers.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Point-Transformers'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 69 (delta 23), reused 52 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (69/69), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66KB0I5pWIXu"
      },
      "source": [
        "!unzip shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
        "%cd /content/Point-Transformers\n",
        "%mkdir data/\n",
        "!mv /content/shapenetcore_partanno_segmentation_benchmark_v0_normal data/shapenetcore_partanno_segmentation_benchmark_v0_normal\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQxvXJyhvbqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ce517e-c12a-4be1-ae53-da9e22342eaa"
      },
      "source": [
        "# !cp -r /content/Point-Transformers/data/shapenetcore_partanno_segmentation_benchmark_v0_normal /content/drive/MyDrive/Datasets/Shapenet"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/Point-Transformers/data/shapenetcore_partanno_segmentation_benchmark_v0_normal': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaLS3UEEj0F7",
        "outputId": "eb73d81c-f9dd-4ac9-c743-0e7bc4426569"
      },
      "source": [
        "!pip install hydra-core --upgrade\n",
        "!pip install plyfile"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: hydra-core in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: omegaconf==2.1.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.1.4)\n",
            "Requirement already satisfied, skipping upgrade: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.8)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.1.*->hydra-core) (5.4.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core) (3.4.1)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/28/a4f08d62adb37c010cf58d04bcff37faa87212ed7acf446eeee9cf75624c/plyfile-0.7.4-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from plyfile) (1.19.5)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFD4qfMB4y53"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/OpenEDS 2021 challenge/val' /content/Point-Transformers/data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RAYjgyzxolw",
        "outputId": "8d8774ee-9679-45a5-dc63-32ed7731d393"
      },
      "source": [
        "%%writefile /content/Point-Transformers/dataset.py\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from pointnet_util import farthest_point_sample, pc_normalize\n",
        "import json\n",
        "import os.path as osp\n",
        "from plyfile import PlyData, PlyElement\n",
        "\n",
        "class ModelNetDataLoader(Dataset):\n",
        "    def __init__(self, root, npoint=1024, split='train', uniform=False, normal_channel=True, cache_size=15000):\n",
        "        self.root = root\n",
        "        self.npoints = npoint\n",
        "        self.uniform = uniform\n",
        "        self.catfile = os.path.join(self.root, 'modelnet40_shape_names.txt')\n",
        "\n",
        "        self.cat = [line.rstrip() for line in open(self.catfile)]\n",
        "        self.classes = dict(zip(self.cat, range(len(self.cat))))\n",
        "        self.normal_channel = normal_channel\n",
        "\n",
        "        shape_ids = {}\n",
        "        shape_ids['train'] = [line.rstrip() for line in open(os.path.join(self.root, 'modelnet40_train.txt'))]\n",
        "        shape_ids['test'] = [line.rstrip() for line in open(os.path.join(self.root, 'modelnet40_test.txt'))]\n",
        "\n",
        "        assert (split == 'train' or split == 'test')\n",
        "        shape_names = ['_'.join(x.split('_')[0:-1]) for x in shape_ids[split]]\n",
        "        # list of (shape_name, shape_txt_file_path) tuple\n",
        "        self.datapath = [(shape_names[i], os.path.join(self.root, shape_names[i], shape_ids[split][i]) + '.txt') for i\n",
        "                         in range(len(shape_ids[split]))]\n",
        "        print('The size of %s data is %d'%(split,len(self.datapath)))\n",
        "\n",
        "        self.cache_size = cache_size  # how many data points to cache in memory\n",
        "        self.cache = {}  # from index to (point_set, cls) tuple\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datapath)\n",
        "\n",
        "    def _get_item(self, index):\n",
        "        if index in self.cache:\n",
        "            point_set, cls = self.cache[index]\n",
        "        else:\n",
        "            fn = self.datapath[index]\n",
        "            cls = self.classes[self.datapath[index][0]]\n",
        "            cls = np.array([cls]).astype(np.int32)\n",
        "            point_set = np.loadtxt(fn[1], delimiter=',').astype(np.float32)\n",
        "            if self.uniform:\n",
        "                point_set = farthest_point_sample(point_set, self.npoints)\n",
        "            else:\n",
        "                point_set = point_set[0:self.npoints,:]\n",
        "\n",
        "            point_set[:, 0:3] = pc_normalize(point_set[:, 0:3])\n",
        "\n",
        "            if not self.normal_channel:\n",
        "                point_set = point_set[:, 0:3]\n",
        "\n",
        "            if len(self.cache) < self.cache_size:\n",
        "                self.cache[index] = (point_set, cls)\n",
        "\n",
        "        return point_set, cls\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self._get_item(index)\n",
        "\n",
        "\n",
        "class PartNormalDataset(Dataset):\n",
        "    def __init__(self, root='./data/shapenetcore_partanno_segmentation_benchmark_v0_normal', npoints=2500, split='train', class_choice=None, normal_channel=False):\n",
        "        self.npoints = npoints\n",
        "        # self.root = root\n",
        "        # self.catfile = os.path.join(self.root, 'synsetoffset2category.txt')\n",
        "        self.cat = {}\n",
        "        self.normal_channel = normal_channel\n",
        "        self.folder = \"val\"\n",
        "        self.data_dir = os.path.join(root, self.folder)\n",
        "\n",
        "        self.datapath = []\n",
        "        for file in os.listdir(self.data_dir):   \n",
        "            if os.path.isdir(osp.join(self.data_dir,file)):\n",
        "                self.datapath.append(file)\n",
        "            else:\n",
        "                print(\"wrong file path, please reconsider your life choices\")\n",
        "                raise IOError \n",
        "\n",
        "        # self.classes = {}\n",
        "        # for i in self.cat.keys():\n",
        "        #     self.classes[i] = self.classes_original[i]\n",
        "\n",
        "        # print(self.classes)\n",
        "        # print(self.datapath)\n",
        "        # Mapping from category ('Chair') to a list of int [10,11,12,13] as segmentation labels\n",
        "        self.seg_classes = {'Pupil' :[0], 'Iris': [1], 'Sclera': [2], 'Eye-lashes': [3], 'Background':[4]}\n",
        "\n",
        "        # for cat in sorted(self.seg_classes.keys()):\n",
        "        #     print(cat, self.seg_classes[cat])\n",
        "\n",
        "        self.cache = {}  # from index to (point_set, cls, seg) tuple\n",
        "        self.cache_size = 20000\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index in self.cache:\n",
        "            point_set, seg = self.cache[index]\n",
        "        else:\n",
        "            fn = self.datapath[index]\n",
        "            data = self.load_point_cloud(fn)\n",
        "            point_set = data[:, 0:3]\n",
        "            labels_path = osp.join(self.data_dir, fn, \"labels.npy\")\n",
        "            seg = np.load(labels_path).astype(np.int32) \n",
        "            # seg = data[:, -1].astype(np.int32)\n",
        "            if len(self.cache) < self.cache_size:\n",
        "                self.cache[index] = (point_set, seg)\n",
        "        point_set[:, 0:3] = pc_normalize(point_set[:, 0:3])\n",
        "\n",
        "        choice = np.random.choice(len(seg), self.npoints, replace=True)\n",
        "        # resample\n",
        "        point_set = point_set[choice, :]\n",
        "        seg = seg[choice]\n",
        "\n",
        "        return point_set, seg\n",
        "\n",
        "    def load_point_cloud(self,filepath):\n",
        "        pointCloudPath = osp.join(self.data_dir,filepath,\"pointcloud.ply\")\n",
        "        \n",
        "        plydata = PlyData.read(pointCloudPath)\n",
        "        return np.array(np.transpose(np.stack((plydata['vertex']['x'],plydata['vertex']['y'],plydata['vertex']['z'])))).astype(np.float32)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datapath)\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "    #     if download and not os.path.exists(self.data_dir):\n",
        "    #         print(\"folder not found, please check dataset\")\n",
        "\n",
        "    #     self.train, self.num_points = train, num_points\n",
        "\n",
        "    #     self.points, self.labels = [],[]\n",
        "    #     for file in os.listdir(self.data_dir):   \n",
        "    #         if os.path.isdir(osp.join(self.data_dir,file)):\n",
        "    #             # print(os.listdir(osp.join(self.filepath,file)))\n",
        "    #             pointCloudPath = osp.join(self.data_dir,file,\"pointcloud.ply\")\n",
        "        \n",
        "    #             plydata = PlyData.read(pointCloudPath)\n",
        "    #             pts = np.array(np.transpose(np.stack((plydata['vertex']['x'],plydata['vertex']['y'],plydata['vertex']['z'])))).astype(np.float32)\n",
        "\n",
        "    #             choice = np.random.choice(len(pts), 4096, replace=True)\n",
        "    #             point_set = pts[choice, :]\n",
        "\n",
        "    #             point_set = point_set - np.expand_dims(np.mean(point_set, axis=0), 0)  # center\n",
        "    #             dist = np.max(np.sqrt(np.sum(point_set ** 2, axis=1)), 0)\n",
        "    #             point_set = point_set / dist  # scale\n",
        "\n",
        "\n",
        "    #             self.points.append(point_set)\n",
        "\n",
        "\n",
        "    #             labels_path = osp.join(self.data_dir, file, \"labels.npy\")\n",
        "    #             label = np.load(labels_path)\n",
        "    #             label = label[choice]\n",
        "    #             self.labels.append(label)\n",
        "\n",
        "    #     self.points = np.stack(self.points)\n",
        "    #     self.labels = np.stack(self.labels)\n",
        "\n",
        "\n",
        "\n",
        "    #     # print(self.points.shape, self.labels.shape)\n",
        "    # def __getitem__(self, idx):\n",
        "    #     pt_idxs = np.arange(0, self.num_points)\n",
        "    #     np.random.shuffle(pt_idxs)\n",
        "\n",
        "    #     current_points = torch.from_numpy(self.points[idx, pt_idxs].copy()).float()\n",
        "    #     current_labels = torch.from_numpy(self.labels[idx, pt_idxs].copy()).long()\n",
        "    #     return current_points, current_labels\n",
        "\n",
        "    # def __len__(self):\n",
        "    #     return int(self.points.shape[0] * self.data_precent)\n",
        "\n",
        "    # def set_num_points(self, pts):\n",
        "    #     self.num_points = pts\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data = PartNormalDataset('/content/Point-Transformers/data', split='train')\n",
        "    DataLoader = torch.utils.data.DataLoader(data, batch_size=12, shuffle=True)\n",
        "    for point,label in DataLoader:\n",
        "        print(point.shape)\n",
        "        print(label.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/Point-Transformers/dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGMI1IO1A4XB",
        "outputId": "a8d73010-8ccf-4893-abcb-1fff735b8676"
      },
      "source": [
        "!python /content/Point-Transformers/dataset.py"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12, 2500, 3])\n",
            "torch.Size([12, 2500])\n",
            "torch.Size([12, 2500, 3])\n",
            "torch.Size([12, 2500])\n",
            "torch.Size([12, 2500, 3])\n",
            "torch.Size([12, 2500])\n",
            "torch.Size([12, 2500, 3])\n",
            "torch.Size([12, 2500])\n",
            "torch.Size([12, 2500, 3])\n",
            "torch.Size([12, 2500])\n",
            "torch.Size([12, 2500, 3])\n",
            "torch.Size([12, 2500])\n",
            "torch.Size([6, 2500, 3])\n",
            "torch.Size([6, 2500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR_orXa0QPIT",
        "outputId": "a743fa44-eba9-494b-d0cf-dc510df1b5a9"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config\tdataset.py  pointnet_util.py  __pycache__  train_cls.py\n",
            "data\tmodels\t    provider.py       README.md    train_partseg.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZM2lLxBk-P3",
        "outputId": "11236b6d-604f-4658-e191-3e8f839c2059"
      },
      "source": [
        "%%writefile /content/Point-Transformers/train_partseg.py\n",
        "\"\"\"\n",
        "Author: Benny\n",
        "Date: Nov 2019\n",
        "\"\"\"\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import datetime\n",
        "import logging\n",
        "import sys\n",
        "import importlib\n",
        "import shutil\n",
        "import provider\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from dataset import PartNormalDataset\n",
        "import hydra\n",
        "import omegaconf\n",
        "\n",
        "\n",
        "# seg_classes = {'Earphone': [16, 17, 18], 'Motorbike': [30, 31, 32, 33, 34, 35], 'Rocket': [41, 42, 43],\n",
        "#                'Car': [8, 9, 10, 11], 'Laptop': [28, 29], 'Cap': [6, 7], 'Skateboard': [44, 45, 46], 'Mug': [36, 37],\n",
        "#                'Guitar': [19, 20, 21], 'Bag': [4, 5], 'Lamp': [24, 25, 26, 27], 'Table': [47, 48, 49],\n",
        "#                'Airplane': [0, 1, 2, 3], 'Pistol': [38, 39, 40], 'Chair': [12, 13, 14, 15], 'Knife': [22, 23]}\n",
        "\n",
        "seg_classes = {'Pupil' :[0], 'Iris': [1], 'Sclera': [2], 'Eye-lashes' :[3], 'Background':[4]}\n",
        "seg_label_to_cat = {}  # {0:Airplane, 1:Airplane, ...49:Table}\n",
        "for cat in seg_classes.keys():\n",
        "    for label in seg_classes[cat]:\n",
        "        seg_label_to_cat[label] = cat\n",
        "\n",
        "\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace=True\n",
        "\n",
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    new_y = torch.eye(num_classes)[y.cpu().data.numpy(),]\n",
        "    if (y.is_cuda):\n",
        "        return new_y.cuda()\n",
        "    return new_y\n",
        "\n",
        "@hydra.main(config_path='config', config_name='partseg')\n",
        "def main(args):\n",
        "    omegaconf.OmegaConf.set_struct(args, False)\n",
        "\n",
        "    '''HYPER PARAMETER'''\n",
        "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    # print(args.pretty())\n",
        "\n",
        "    root = hydra.utils.to_absolute_path('data/')\n",
        "\n",
        "    TRAIN_DATASET = PartNormalDataset(root=root, npoints=args.num_point, split='trainval', normal_channel=args.normal)\n",
        "    trainDataLoader = torch.utils.data.DataLoader(TRAIN_DATASET, batch_size=args.batch_size, shuffle=True, num_workers=10, drop_last=True)\n",
        "    TEST_DATASET = PartNormalDataset(root=root, npoints=args.num_point, split='test', normal_channel=args.normal)\n",
        "    testDataLoader = torch.utils.data.DataLoader(TEST_DATASET, batch_size=args.batch_size, shuffle=False, num_workers=10)\n",
        "\n",
        "    '''MODEL LOADING'''\n",
        "    # args.input_dim = (6 if args.normal else 3) + 16\n",
        "    args.input_dim = (3 if args.normal else 3)\n",
        "    args.num_class = 5\n",
        "    num_category = 5\n",
        "    num_part = args.num_class\n",
        "    shutil.copy(hydra.utils.to_absolute_path('models/{}/model.py'.format(args.model.name)), '.')\n",
        "\n",
        "    classifier = getattr(importlib.import_module('models.{}.model'.format(args.model.name)), 'PointTransformerSeg')(args).cuda()\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load('best_model.pth')\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "        logger.info('Use pretrain model')\n",
        "    except:\n",
        "        logger.info('No existing model, starting training from scratch...')\n",
        "        start_epoch = 0\n",
        "\n",
        "    if args.optimizer == 'Adam':\n",
        "        optimizer = torch.optim.Adam(\n",
        "            classifier.parameters(),\n",
        "            lr=args.learning_rate,\n",
        "            betas=(0.9, 0.999),\n",
        "            eps=1e-08,\n",
        "            weight_decay=args.weight_decay\n",
        "        )\n",
        "    else:\n",
        "        optimizer = torch.optim.SGD(classifier.parameters(), lr=args.learning_rate, momentum=0.9)\n",
        "\n",
        "    def bn_momentum_adjust(m, momentum):\n",
        "        if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
        "            m.momentum = momentum\n",
        "\n",
        "    LEARNING_RATE_CLIP = 1e-5\n",
        "    MOMENTUM_ORIGINAL = 0.1\n",
        "    MOMENTUM_DECCAY = 0.5\n",
        "    MOMENTUM_DECCAY_STEP = args.step_size\n",
        "\n",
        "    best_acc = 0\n",
        "    global_epoch = 0\n",
        "    best_class_avg_iou = 0\n",
        "    best_inctance_avg_iou = 0\n",
        "\n",
        "    for epoch in range(start_epoch, args.epoch):\n",
        "        mean_correct = []\n",
        "\n",
        "        logger.info('Epoch %d (%d/%s):' % (global_epoch + 1, epoch + 1, args.epoch))\n",
        "        '''Adjust learning rate and BN momentum'''\n",
        "        lr = max(args.learning_rate * (args.lr_decay ** (epoch // args.step_size)), LEARNING_RATE_CLIP)\n",
        "        logger.info('Learning rate:%f' % lr)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        momentum = MOMENTUM_ORIGINAL * (MOMENTUM_DECCAY ** (epoch // MOMENTUM_DECCAY_STEP))\n",
        "        if momentum < 0.01:\n",
        "            momentum = 0.01\n",
        "        print('BN momentum updated to: %f' % momentum)\n",
        "        classifier = classifier.apply(lambda x: bn_momentum_adjust(x, momentum))\n",
        "        classifier = classifier.train()\n",
        "\n",
        "        '''learning one epoch'''\n",
        "        for i, (points,  target) in tqdm(enumerate(trainDataLoader), total=len(trainDataLoader), smoothing=0.9):\n",
        "            points = points.data.numpy()\n",
        "            points[:, :, 0:3] = provider.random_scale_point_cloud(points[:, :, 0:3])\n",
        "            points[:, :, 0:3] = provider.shift_point_cloud(points[:, :, 0:3])\n",
        "            points = torch.Tensor(points)\n",
        "            # k = torch.cat([points, to_categorical(label, num_category).repeat(1, points.shape[1], 1)], -1)\n",
        "            # print(points.shape, label, target.shape,k.shape)\n",
        "            points,  target = points.float().cuda(), target.long().cuda()\n",
        "            optimizer.zero_grad()\n",
        "            seg_pred = classifier(points)\n",
        "            # seg_pred = classifier(torch.cat([points, to_categorical(label, num_category).repeat(1, points.shape[1], 1)], -1))\n",
        "            # print(seg_pred.shape, target[:,10])\n",
        "            seg_pred = seg_pred.contiguous().view(-1, num_part)\n",
        "            target = target.view(-1, 1)[:, 0]\n",
        "            pred_choice = seg_pred.data.max(1)[1]\n",
        "\n",
        "            correct = pred_choice.eq(target.data).cpu().sum()\n",
        "            mean_correct.append(correct.item() / (args.batch_size * args.num_point))\n",
        "            loss = criterion(seg_pred, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_instance_acc = np.mean(mean_correct)\n",
        "        logger.info('Train accuracy is: %.5f' % train_instance_acc)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            test_metrics = {}\n",
        "            total_correct = 0\n",
        "            total_seen = 0\n",
        "            total_seen_class = [0 for _ in range(num_part)]\n",
        "            total_correct_class = [0 for _ in range(num_part)]\n",
        "            shape_ious = {cat: [] for cat in seg_classes.keys()}\n",
        "            seg_label_to_cat = {}  # {0:Airplane, 1:Airplane, ...49:Table}\n",
        "\n",
        "            for cat in seg_classes.keys():\n",
        "                for label in seg_classes[cat]:\n",
        "                    seg_label_to_cat[label] = cat\n",
        "\n",
        "            classifier = classifier.eval()\n",
        "\n",
        "            for batch_id, (points, label, target) in tqdm(enumerate(testDataLoader), total=len(testDataLoader), smoothing=0.9):\n",
        "                cur_batch_size, NUM_POINT, _ = points.size()\n",
        "                points, label, target = points.float().cuda(), label.long().cuda(), target.long().cuda()\n",
        "                seg_pred = classifier(torch.cat([points, to_categorical(label, num_category).repeat(1, points.shape[1], 1)], -1))\n",
        "                cur_pred_val = seg_pred.cpu().data.numpy()\n",
        "                cur_pred_val_logits = cur_pred_val\n",
        "                cur_pred_val = np.zeros((cur_batch_size, NUM_POINT)).astype(np.int32)\n",
        "                target = target.cpu().data.numpy()\n",
        "\n",
        "                for i in range(cur_batch_size):\n",
        "                    cat = seg_label_to_cat[target[i, 0]]\n",
        "                    logits = cur_pred_val_logits[i, :, :]\n",
        "                    cur_pred_val[i, :] = np.argmax(logits[:, seg_classes[cat]], 1) + seg_classes[cat][0]\n",
        "\n",
        "                correct = np.sum(cur_pred_val == target)\n",
        "                total_correct += correct\n",
        "                total_seen += (cur_batch_size * NUM_POINT)\n",
        "\n",
        "                for l in range(num_part):\n",
        "                    total_seen_class[l] += np.sum(target == l)\n",
        "                    total_correct_class[l] += (np.sum((cur_pred_val == l) & (target == l)))\n",
        "\n",
        "                for i in range(cur_batch_size):\n",
        "                    segp = cur_pred_val[i, :]\n",
        "                    segl = target[i, :]\n",
        "                    cat = seg_label_to_cat[segl[0]]\n",
        "                    part_ious = [0.0 for _ in range(len(seg_classes[cat]))]\n",
        "                    for l in seg_classes[cat]:\n",
        "                        if (np.sum(segl == l) == 0) and (\n",
        "                                np.sum(segp == l) == 0):  # part is not present, no prediction as well\n",
        "                            part_ious[l - seg_classes[cat][0]] = 1.0\n",
        "                        else:\n",
        "                            part_ious[l - seg_classes[cat][0]] = np.sum((segl == l) & (segp == l)) / float(\n",
        "                                np.sum((segl == l) | (segp == l)))\n",
        "                    shape_ious[cat].append(np.mean(part_ious))\n",
        "\n",
        "            all_shape_ious = []\n",
        "            for cat in shape_ious.keys():\n",
        "                for iou in shape_ious[cat]:\n",
        "                    all_shape_ious.append(iou)\n",
        "                shape_ious[cat] = np.mean(shape_ious[cat])\n",
        "            mean_shape_ious = np.mean(list(shape_ious.values()))\n",
        "            test_metrics['accuracy'] = total_correct / float(total_seen)\n",
        "            test_metrics['class_avg_accuracy'] = np.mean(\n",
        "                np.array(total_correct_class) / np.array(total_seen_class, dtype=np.float))\n",
        "            for cat in sorted(shape_ious.keys()):\n",
        "                logger.info('eval mIoU of %s %f' % (cat + ' ' * (14 - len(cat)), shape_ious[cat]))\n",
        "            test_metrics['class_avg_iou'] = mean_shape_ious\n",
        "            test_metrics['inctance_avg_iou'] = np.mean(all_shape_ious)\n",
        "\n",
        "        logger.info('Epoch %d test Accuracy: %f  Class avg mIOU: %f   Inctance avg mIOU: %f' % (\n",
        "            epoch + 1, test_metrics['accuracy'], test_metrics['class_avg_iou'], test_metrics['inctance_avg_iou']))\n",
        "        if (test_metrics['inctance_avg_iou'] >= best_inctance_avg_iou):\n",
        "            logger.info('Save model...')\n",
        "            savepath = 'best_model.pth'\n",
        "            logger.info('Saving at %s' % savepath)\n",
        "            state = {\n",
        "                'epoch': epoch,\n",
        "                'train_acc': train_instance_acc,\n",
        "                'test_acc': test_metrics['accuracy'],\n",
        "                'class_avg_iou': test_metrics['class_avg_iou'],\n",
        "                'inctance_avg_iou': test_metrics['inctance_avg_iou'],\n",
        "                'model_state_dict': classifier.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }\n",
        "            torch.save(state, savepath)\n",
        "            logger.info('Saving model....')\n",
        "\n",
        "        if test_metrics['accuracy'] > best_acc:\n",
        "            best_acc = test_metrics['accuracy']\n",
        "        if test_metrics['class_avg_iou'] > best_class_avg_iou:\n",
        "            best_class_avg_iou = test_metrics['class_avg_iou']\n",
        "        if test_metrics['inctance_avg_iou'] > best_inctance_avg_iou:\n",
        "            best_inctance_avg_iou = test_metrics['inctance_avg_iou']\n",
        "        logger.info('Best accuracy is: %.5f' % best_acc)\n",
        "        logger.info('Best class avg mIOU is: %.5f' % best_class_avg_iou)\n",
        "        logger.info('Best inctance avg mIOU is: %.5f' % best_inctance_avg_iou)\n",
        "        global_epoch += 1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/Point-Transformers/train_partseg.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-VLLEDssCAN",
        "outputId": "11ee5369-ff21-47c8-c1ec-281b196f5738"
      },
      "source": [
        "%%writefile /content/Point-Transformers/config/partseg.yaml\n",
        "batch_size: 12\n",
        "epoch: 200\n",
        "learning_rate: 1e-3\n",
        "gpu: 1\n",
        "num_point: 1024\n",
        "optimizer: Adam\n",
        "weight_decay: 1e-4\n",
        "normal: False\n",
        "lr_decay: 0.5\n",
        "step_size: 20\n",
        "\n",
        "defaults:\n",
        "  - model: Hengshuang\n",
        "\n",
        "hydra:\n",
        "  run:\n",
        "    dir: log/partseg/${model.name}\n",
        "\n",
        "  sweep:\n",
        "    dir: log/partseg\n",
        "    subdir: ${model.name}"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/Point-Transformers/config/partseg.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy2V81Otpmvh",
        "outputId": "18551eed-f443-4b8c-e1af-33097fdb156a"
      },
      "source": [
        "%cd /content/Point-Transformers\n",
        "%ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Point-Transformers\n",
            "\u001b[0m\u001b[01;34mconfig\u001b[0m/  dataset.py  pointnet_util.py  \u001b[01;34m__pycache__\u001b[0m/  train_cls.py\n",
            "\u001b[01;34mdata\u001b[0m/    \u001b[01;34mmodels\u001b[0m/     provider.py       README.md     train_partseg.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOiFDVPoj-uj",
        "outputId": "84cb661f-e1b5-4d87-f010-3a6096bb50b3"
      },
      "source": [
        "!python /content/Point-Transformers/train_partseg.py"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hydra/core/default_element.py:127: UserWarning: In 'model/Hengshuang': Usage of deprecated keyword in package header '# @package _group_'.\n",
            "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
            "  See {url} for more information\"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "[2021-06-16 18:14:45,591][__main__][INFO] - No existing model, starting training from scratch...\n",
            "[2021-06-16 18:14:45,592][__main__][INFO] - Epoch 1 (1/200):\n",
            "[2021-06-16 18:14:45,592][__main__][INFO] - Learning rate:0.001000\n",
            "BN momentum updated to: 0.100000\n",
            "100% 6/6 [00:09<00:00,  1.56s/it]\n",
            "[2021-06-16 18:14:55,253][__main__][INFO] - Train accuracy is: 0.66634\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            "Error executing job with overrides: []\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Point-Transformers/train_partseg.py\", line 166, in main\n",
            "    for batch_id, (points, label, target) in tqdm(enumerate(testDataLoader), total=len(testDataLoader), smoothing=0.9):\n",
            "ValueError: not enough values to unpack (expected 3, got 2)\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNc48ssnrscM"
      },
      "source": [
        "## Part 2: Point transformers using S3DIS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdjyhQBbsF6g",
        "outputId": "e9b9959b-381d-4c0f-9b14-b6a224167669"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 16 14:53:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    70W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMLwtBilrnxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5023cd98-6b20-4dba-dd79-1b1a38aca412"
      },
      "source": [
        "# !wget --no-check-certificat https://shapenet.cs.stanford.edu/media/indoor3d_sem_seg_hdf5_data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-14 07:03:11--  https://shapenet.cs.stanford.edu/media/indoor3d_sem_seg_hdf5_data.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1679781976 (1.6G) [application/zip]\n",
            "Saving to: ‘indoor3d_sem_seg_hdf5_data.zip’\n",
            "\n",
            "indoor3d_sem_seg_hd 100%[===================>]   1.56G  1.31MB/s    in 10m 57s \n",
            "\n",
            "2021-06-14 07:14:08 (2.44 MB/s) - ‘indoor3d_sem_seg_hdf5_data.zip’ saved [1679781976/1679781976]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJi7ipHKVJx-"
      },
      "source": [
        "# !unzip /content/indoor3d_sem_seg_hdf5_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp5GkvueXw4d"
      },
      "source": [
        "# import h5py\n",
        "# def load_data_file(name):\n",
        "#     f = h5py.File(name, \"r\")\n",
        "#     data = f[\"data\"][:]\n",
        "#     label = f[\"label\"][:]\n",
        "#     return data, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkk-3L-9YCoO",
        "outputId": "2bc0f4c5-f05c-48ce-a881-9c6abd110e07"
      },
      "source": [
        "# d, l = load_data_file('/content/Point-Transformers/indoor3d_sem_seg_hdf5_data/ply_data_all_0.h5')\n",
        "# print(d.shape, l.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 4096, 9) (1000, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6TodaXgZ02Y",
        "outputId": "ea989d6f-6445-407e-86d0-f5c36e60a531"
      },
      "source": [
        "# %cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IUW20UxZ_0e",
        "outputId": "b920f776-adae-4bee-e817-1485b1f6bcdc"
      },
      "source": [
        "!git clone https://github.com/POSTECH-CVLab/point-transformer.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'point-transformer'...\n",
            "remote: Enumerating objects: 341, done.\u001b[K\n",
            "remote: Counting objects: 100% (341/341), done.\u001b[K\n",
            "remote: Compressing objects: 100% (238/238), done.\u001b[K\n",
            "remote: Total 341 (delta 183), reused 229 (delta 93), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (341/341), 78.57 KiB | 924.00 KiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xsHvcikaB9r",
        "outputId": "e99e4aa2-c169-4381-b9ec-b7b271366a9b"
      },
      "source": [
        "%cd point-transformer/\n",
        "%ls\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/point-transformer\n",
            "LICENSE.md   \u001b[0m\u001b[01;34mpoint_transformer\u001b[0m/      pyproject.toml  requirements.txt  tox.ini\n",
            "MANIFEST.in  \u001b[01;34mpoint_transformer_lib\u001b[0m/  README.rst      setup.py\n",
            "Processing ./point_transformer_lib\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting msgpack-numpy\n",
            "  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.99)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.1.0)\n",
            "Collecting hydra-core==0.11.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/2f/e8dbf1266062d4041cbdcd725cb91210d9811aefb9cdf5fc04cb381bf9b9/hydra_core-0.11.3-py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.8MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning==0.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/9e/db4e1e3036e045a25d5c37617ded31a673a61f4befc62c5231818810b3a7/pytorch-lightning-0.7.1.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 7.3MB/s \n",
            "\u001b[?25hCollecting open3d==0.12.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/9c/dd30378d9334396894a02c296d74b265fba0ff85838ceef12385cd4ebff9/open3d-0.12.0-cp37-cp37m-manylinux2014_x86_64.whl (188.4MB)\n",
            "\u001b[K     |████████████████████████████████| 188.4MB 88kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from point-transformer-ops==0.1.0->-r requirements.txt (line 10)) (1.8.1+cu101)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from msgpack-numpy->-r requirements.txt (line 2)) (1.0.2)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->-r requirements.txt (line 4)) (1.5.2)\n",
            "Collecting omegaconf<1.5,>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/53/d285f1faa36eca666f6d04ac17c5f3a9e72cedaeb530e663fdc025209780/omegaconf-1.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.35.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (2.5.0)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 21.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0.0->-r requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0.0->-r requirements.txt (line 8)) (3.5.1)\n",
            "Collecting addict\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0.0->-r requirements.txt (line 8)) (0.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0.0->-r requirements.txt (line 8)) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0.0->-r requirements.txt (line 8)) (7.6.3)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/28/a4f08d62adb37c010cf58d04bcff37faa87212ed7acf446eeee9cf75624c/plyfile-0.7.4-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0.0->-r requirements.txt (line 8)) (3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0.0->-r requirements.txt (line 8)) (1.1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->point-transformer-ops==0.1.0->-r requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from omegaconf<1.5,>=1.4->hydra-core==0.11.3->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (3.12.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (1.31.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->open3d==0.12.0.0->-r requirements.txt (line 8)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->open3d==0.12.0.0->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->open3d==0.12.0.0->-r requirements.txt (line 8)) (2.4.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.22.2.post1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (5.1.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (5.1.3)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (5.3.5)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.10.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (5.0.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (4.10.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (4.7.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->open3d==0.12.0.0->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->open3d==0.12.0.0->-r requirements.txt (line 8)) (5.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->open3d==0.12.0.0->-r requirements.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (4.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (4.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->open3d==0.12.0.0->-r requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->open3d==0.12.0.0->-r requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (2.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d==0.12.0.0->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d==0.12.0.0->-r requirements.txt (line 8)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d==0.12.0.0->-r requirements.txt (line 8)) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.1->-r requirements.txt (line 7)) (0.4.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d==0.12.0.0->-r requirements.txt (line 8)) (0.2.5)\n",
            "Building wheels for collected packages: pytorch-lightning, point-transformer-ops, future\n",
            "  Building wheel for pytorch-lightning (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-lightning: filename=pytorch_lightning-0.7.1-cp37-none-any.whl size=145330 sha256=f7b0695d1c02da853fc7c8a08a942f7169ad6023f77f2d77b954c932929f152e\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/93/61/14094d2116ff739513dda993007501ae5701b78386b39d5912\n",
            "  Building wheel for point-transformer-ops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for point-transformer-ops: filename=point_transformer_ops-0.1.0-cp37-cp37m-linux_x86_64.whl size=5415562 sha256=4b64d9d7fef76b925ba4ce32ec75e763766c41a63ebb3d3e3bc7c22575b81c60\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r69uet5m/wheels/f7/62/54/9c2001c27dfd0e9a91559fbd41acfe0db7070cd94cd66e6d01\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=36beaaa6a3aea1685cc624f1c4657f212af9a00d33e72d6f1bde4d65c6fc4551\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built pytorch-lightning point-transformer-ops future\n",
            "Installing collected packages: msgpack-numpy, omegaconf, hydra-core, future, pytorch-lightning, addict, plyfile, open3d, point-transformer-ops\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed addict-2.4.0 future-0.18.2 hydra-core-0.11.3 msgpack-numpy-0.4.7.1 omegaconf-1.4.1 open3d-0.12.0 plyfile-0.7.4 point-transformer-ops-0.1.0 pytorch-lightning-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y5a9XeaaJ9i",
        "outputId": "98ee571d-258d-4220-99ba-0c7d6982a98a"
      },
      "source": [
        "!pip install -e ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/point-transformer\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: hydra-core==0.11.3 in /usr/local/lib/python3.7/dist-packages (from point-transformer==0.1.0) (0.11.3)\n",
            "Requirement already satisfied: pytorch-lightning==0.7.1 in /usr/local/lib/python3.7/dist-packages (from point-transformer==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: omegaconf<1.5,>=1.4 in /usr/local/lib/python3.7/dist-packages (from hydra-core==0.11.3->point-transformer==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.7.1->point-transformer==0.1.0) (1.19.5)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.7.1->point-transformer==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.35.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.7.1->point-transformer==0.1.0) (4.41.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.7.1->point-transformer==0.1.0) (0.18.2)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.7.1->point-transformer==0.1.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from omegaconf<1.5,>=1.4->hydra-core==0.11.3->point-transformer==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from omegaconf<1.5,>=1.4->hydra-core==0.11.3->point-transformer==0.1.0) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (57.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (3.3.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (1.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->pytorch-lightning==0.7.1->point-transformer==0.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.1->point-transformer==0.1.0) (0.4.8)\n",
            "Installing collected packages: point-transformer\n",
            "  Running setup.py develop for point-transformer\n",
            "Successfully installed point-transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W3-aXSZuL1O"
      },
      "source": [
        "!mkdir /content/point-transformer/point_transformer/data/val"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEDEgQT0s50w"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/OpenEDS 2021 challenge/val' /content/point-transformer/point_transformer/data/val"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWJz1WE5I2_B",
        "outputId": "88131528-9b24-4c6e-cf7c-5aeb42698998"
      },
      "source": [
        "%cd /content/point-transformer"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/point-transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XehWJNGAkrTo",
        "outputId": "9bae4c31-0099-4197-8ae6-42865d89a031"
      },
      "source": [
        "# %%writefile /content/point-transformer/point_transformer/config/config.yaml\n",
        "# defaults:\n",
        "#     - task: cls\n",
        "#     - model: point_transformer\n",
        "#     - task_model: ${defaults.0.task}-${defaults.1.model}\n",
        "\n",
        "# hydra:\n",
        "#   run:\n",
        "#     dir: outputs\n",
        "\n",
        "# gpus:\n",
        "#     - 0\n",
        "\n",
        "# optimizer: ???\n",
        "\n",
        "# task_model: ???\n",
        "\n",
        "# model: ???\n",
        "\n",
        "# distrib_backend: dp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/point-transformer/point_transformer/config/config.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1R9FUGfldIH",
        "outputId": "a660fcd6-b296-4dba-a047-dc56bccda875"
      },
      "source": [
        "%%writefile /content/point-transformer/point_transformer/data/Indoor3DSemSegLoader.py\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from plyfile import PlyData, PlyElement\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import os.path as osp\n",
        "\n",
        "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "\n",
        "def _get_data_files(list_filename):\n",
        "    with open(list_filename) as f:\n",
        "        return [line.rstrip() for line in f]\n",
        "\n",
        "\n",
        "def _load_data_file(name):\n",
        "    f = h5py.File(name, \"r\")\n",
        "    data = f[\"data\"][:]\n",
        "    label = f[\"label\"][:]\n",
        "    return data, label\n",
        "\n",
        "\n",
        "class Indoor3DSemSeg(data.Dataset):\n",
        "    def __init__(self, num_points, train=True, download=False, data_precent=1.0):\n",
        "        super().__init__()\n",
        "        self.data_precent = data_precent\n",
        "        self.folder = \"val/val\"\n",
        "        self.data_dir = os.path.join(BASE_DIR, self.folder)\n",
        "        self.url = (\n",
        "            \"https://shapenet.cs.stanford.edu/media/indoor3d_sem_seg_hdf5_data.zip\"\n",
        "        )\n",
        "\n",
        "        if download and not os.path.exists(self.data_dir):\n",
        "            # zipfile = os.path.join(BASE_DIR, os.path.basename(self.url))\n",
        "            # subprocess.check_call(\n",
        "            #     shlex.split(\"curl {} -o {}\".format(self.url, zipfile))\n",
        "            # )\n",
        "\n",
        "            # subprocess.check_call(\n",
        "            #     shlex.split(\"unzip {} -d {}\".format(zipfile, BASE_DIR))\n",
        "            # )\n",
        "\n",
        "            # subprocess.check_call(shlex.split(\"rm {}\".format(zipfile)))\n",
        "            print(\"folder not found, please check dataset\")\n",
        "\n",
        "        self.train, self.num_points = train, num_points\n",
        "\n",
        "        # all_files = _get_data_files(os.path.join(self.data_dir, \"all_files.txt\"))\n",
        "        # room_filelist = _get_data_files(\n",
        "        #     os.path.join(self.data_dir, \"room_filelist.txt\")\n",
        "        # )\n",
        "\n",
        "        # data_batchlist, label_batchlist = [], []\n",
        "        # for f in all_files:\n",
        "        #     data, label = _load_data_file(os.path.join(BASE_DIR, f))\n",
        "        #     data_batchlist.append(data)\n",
        "        #     label_batchlist.append(label)\n",
        "\n",
        "        # data_batches = np.concatenate(data_batchlist, 0)\n",
        "        # labels_batches = np.concatenate(label_batchlist, 0)\n",
        "\n",
        "        # test_area = \"Area_5\"\n",
        "        # train_idxs, test_idxs = [], []\n",
        "        # for i, room_name in enumerate(room_filelist):\n",
        "        #     if test_area in room_name:\n",
        "        #         test_idxs.append(i)\n",
        "        #     else:\n",
        "        #         train_idxs.append(i)\n",
        "\n",
        "        # if self.train:\n",
        "        #     self.points = data_batches[train_idxs, ...]\n",
        "        #     self.labels = labels_batches[train_idxs, ...]\n",
        "        # else:\n",
        "        #     self.points = data_batches[test_idxs, ...]\n",
        "        #     self.labels = labels_batches[test_idxs, ...]\n",
        "\n",
        "        self.points, self.labels = [],[]\n",
        "        for file in os.listdir(self.data_dir):   \n",
        "            if os.path.isdir(osp.join(self.data_dir,file)):\n",
        "                # print(os.listdir(osp.join(self.filepath,file)))\n",
        "                pointCloudPath = osp.join(self.data_dir,file,\"pointcloud.ply\")\n",
        "        \n",
        "                plydata = PlyData.read(pointCloudPath)\n",
        "                pts = np.array(np.transpose(np.stack((plydata['vertex']['x'],plydata['vertex']['y'],plydata['vertex']['z'])))).astype(np.float32)\n",
        "\n",
        "                choice = np.random.choice(len(pts), 4096, replace=True)\n",
        "                point_set = pts[choice, :]\n",
        "\n",
        "                point_set = point_set - np.expand_dims(np.mean(point_set, axis=0), 0)  # center\n",
        "                dist = np.max(np.sqrt(np.sum(point_set ** 2, axis=1)), 0)\n",
        "                point_set = point_set / dist  # scale\n",
        "\n",
        "\n",
        "                self.points.append(point_set)\n",
        "\n",
        "\n",
        "                labels_path = osp.join(self.data_dir, file, \"labels.npy\")\n",
        "                label = np.load(labels_path)\n",
        "                label = label[choice]\n",
        "                self.labels.append(label)\n",
        "\n",
        "        self.points = np.stack(self.points)\n",
        "        self.labels = np.stack(self.labels)\n",
        "\n",
        "\n",
        "\n",
        "        # print(self.points.shape, self.labels.shape)\n",
        "    def __getitem__(self, idx):\n",
        "        pt_idxs = np.arange(0, self.num_points)\n",
        "        np.random.shuffle(pt_idxs)\n",
        "\n",
        "        current_points = torch.from_numpy(self.points[idx, pt_idxs].copy()).float()\n",
        "        current_labels = torch.from_numpy(self.labels[idx, pt_idxs].copy()).long()\n",
        "        return current_points, current_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(self.points.shape[0] * self.data_precent)\n",
        "\n",
        "    def set_num_points(self, pts):\n",
        "        self.num_points = pts\n",
        "\n",
        "    def randomize(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dset = Indoor3DSemSeg(16)\n",
        "    print(dset[0])\n",
        "    print(len(dset))\n",
        "    dloader = torch.utils.data.DataLoader(dset, batch_size=32, shuffle=True)\n",
        "    for i, data in enumerate(dloader, 0):\n",
        "        inputs, labels = data\n",
        "        if i == len(dloader) - 1:\n",
        "            print(inputs.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/point-transformer/point_transformer/data/Indoor3DSemSegLoader.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuSaMpNCaOz7",
        "outputId": "9f2868d0-45c8-4d84-e760-093d4fdb07bc"
      },
      "source": [
        "!python -m point_transformer.train task=partseg batch_size=8"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-06-16 14:11:05,575][root][INFO] - GPU available: True, used: True\n",
            "[2021-06-16 14:11:05,576][root][INFO] - VISIBLE GPUS: 0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/point-transformer/point_transformer/train.py\", line 59, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hydra/main.py\", line 24, in decorated_main\n",
            "    strict=strict,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hydra/_internal/utils.py\", line 174, in run_hydra\n",
            "    overrides=args.overrides,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hydra/_internal/hydra.py\", line 86, in run\n",
            "    job_subdir_key=None,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hydra/plugins/common/utils.py\", line 109, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "  File \"/content/point-transformer/point_transformer/train.py\", line 55, in main\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 571, in fit\n",
            "    model.prepare_data()\n",
            "  File \"/content/point-transformer/point_transformer/models/point_transformer_seg.py\", line 106, in prepare_data\n",
            "    self.train_dset = PartNormalDataset(self.hparams[\"num_points\"], 'trainval')\n",
            "  File \"/content/point-transformer/point_transformer/data/ShapeNetPartLoader.py\", line 31, in __init__\n",
            "    with open(self.catfile, 'r') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/root/data/shapenetcore_partanno_segmentation_benchmark_v0_normal/synsetoffset2category.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UESZGymFpRk8"
      },
      "source": [
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from plyfile import PlyData, PlyElement\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import os.path as osp\n",
        "\n",
        "data_dir = '/content/point-transformer/point_transformer/data/val/val'\n",
        "points, labels = [],[]\n",
        "for file in os.listdir('/content/point-transformer/point_transformer/data/val/val'):   \n",
        "    if os.path.isdir(osp.join(data_dir,file)):\n",
        "        # print(os.listdir(osp.join(self.filepath,file)))\n",
        "        pointCloudPath = osp.join(data_dir,file,\"pointcloud.ply\")\n",
        "\n",
        "        plydata = PlyData.read(pointCloudPath)\n",
        "        pts = np.array(np.transpose(np.stack((plydata['vertex']['x'],plydata['vertex']['y'],plydata['vertex']['z'])))).astype(np.float32)\n",
        "\n",
        "        choice = np.random.choice(len(pts), 4096, replace=True)\n",
        "        point_set = pts[choice, :]\n",
        "\n",
        "        point_set = point_set - np.expand_dims(np.mean(point_set, axis=0), 0)  # center\n",
        "        dist = np.max(np.sqrt(np.sum(point_set ** 2, axis=1)), 0)\n",
        "        point_set = point_set / dist  # scale\n",
        "\n",
        "\n",
        "        points.append(point_set)\n",
        "        \n",
        "\n",
        "        labels_path = osp.join(data_dir, file, \"labels.npy\")\n",
        "        label = np.load(labels_path)\n",
        "        label = label[choice]\n",
        "        labels.append(label)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOxHsy3lyerE",
        "outputId": "d17ca7ed-a017-4191-b591-db77a933c668"
      },
      "source": [
        "ots = np.stack(labels)\n",
        "ots.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYNoNvkENhQa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}